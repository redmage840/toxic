{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis of Wikipedia Comments\n",
    "# Comments are classified (model trained) based on Wikipedia Editor Comments, unanimously judged by those Editors\n",
    "#   to be 'toxic' OR 'not toxic'\n",
    "# Mostly outdated word embeddings/vectorizations based on tf-idf and count vectorizer\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "# Merge comments with unanimous score file. Merge the first entry of scores grouped on 'review_id' with comments.\n",
    "comments = pd.read_csv('res/toxicity_annotated_comments_unanimous.tsv', sep='\\t')\n",
    "scores = pd.read_csv('res/toxicity_annotations_unanimous.tsv', sep='\\t')\n",
    "uniqueScores = scores[['review_id', 'toxicity']].groupby('review_id', as_index=False).first()\n",
    "df = pd.merge(comments, uniqueScores, on=\"review_id\")\n",
    "\n",
    "df = df[['review_id','comment', 'toxicity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample 'not toxic' comments\n",
    "# Equalize number of 'toxic' AND 'not toxic' comments for training\n",
    "\n",
    "df = df.groupby('toxicity', as_index=False).head(171)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open non-unanimously classified comments into df2, (we will predict the sentiment of these, 'toxic' OR 'not-toxic')\n",
    "# 'Toxic' OR 'not-toxic' of non-unanimous comments is determined by averaging and rounding to 'zero' OR 'one'\n",
    "\n",
    "comments2 = pd.read_csv('res/toxicity_annotated_comments.tsv', sep='\\t')\n",
    "\n",
    "scores2 = \\\n",
    "pd.read_csv('res/toxicity_annotations.tsv', sep='\\t').groupby('review_id', as_index=False)['toxicity'].mean().round()\n",
    "\n",
    "df2 = pd.merge(comments2, scores2, on='review_id')\n",
    "\n",
    "df2 = df2[['review_id','comment','toxicity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove HTML elements and 'NEWLINE_TOKEN'\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "df['cleaned_comment'] = df.comment.apply(lambda x: BeautifulSoup(x, 'html5lib').get_text())\n",
    "df['cleaned_comment'] = df.cleaned_comment.apply(lambda x: x.replace('NEWLINE_TOKEN', ''))\n",
    "\n",
    "df2['cleaned_comment'] = df2.comment.apply(lambda x: BeautifulSoup(x, 'html5lib').get_text())\n",
    "df2['cleaned_comment'] = df2.cleaned_comment.apply(lambda x: x.replace('NEWLINE_TOKEN', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test results using this or not\n",
    "# Remove non-(alpha|whitespace|apostrophe) chars, change to lowercase\n",
    "# import re\n",
    "\n",
    "# df['cleaned_comment'] = df.cleaned_comment.apply(lambda x: re.sub(\"[^a-zA-Z\\s']\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_set, test_set = train_test_split(df, test_size=0.3, random_state=666)\n",
    "all_words_train = df.cleaned_comment\n",
    "all_words_test = df2.cleaned_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer (note: max_features changed from 4500 to 1000)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vec = TfidfVectorizer(stop_words='english', min_df=1, max_df=.4, norm='l2', ngram_range=(1,2), max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words Vectorizer (note: max_features changed from 1000 to 100)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vec = CountVectorizer(stop_words=\"english\", min_df=2, max_df=.6, ngram_range=(1,2), max_features=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "combined_features = FeatureUnion([(\"bagOwords\", count_vec), (\"tfidf\", tfidf_vec)])\n",
    "\n",
    "X_train = combined_features.fit_transform(all_words_train)\n",
    "X_test = combined_features.transform(all_words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logRegClsfr = LogisticRegression(fit_intercept=True, penalty='l2', solver='newton-cg')\n",
    "\n",
    "params = {\n",
    "    #'penalty': ('l1', 'l2')\n",
    "    #'fit_intercept': (True, False)\n",
    "    #'solver' : ('newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga')\n",
    "}\n",
    "\n",
    "logRegClsfr.fit(X_train, df.toxicity)\n",
    "print(logRegClsfr.score(X_test, df2.toxicity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.744\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgdClsfr = SGDClassifier(loss='modified_huber', penalty='l2', fit_intercept=True, max_iter=1000)\n",
    "\n",
    "params = {\n",
    "    \n",
    "    #\"loss\": ('hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'),\n",
    "    #\"penalty\": ('none', 'l2', 'l1', 'elasticnet'),\n",
    "    #\"fit_intercept\": (True,False),\n",
    "    #\"max_iter\": (5,10,20,50,150,500,1000)\n",
    "}\n",
    "\n",
    "sgdClsfr.fit(X_train, df.toxicity)\n",
    "\n",
    "print(sgdClsfr.score(X_test, df2.toxicity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.756\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svcClsfr = SVC(C=1.5, kernel='linear', degree=3, shrinking=True, probability=True, decision_function_shape='ovr')\n",
    "\n",
    "# C=1.0, kernel=’rbf’, degree=3, gamma=’auto’, coef0=0.0, shrinking=True, probability=False, tol=0.001,\n",
    "# cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape=’ovr’, random_state=None\n",
    "params = {\n",
    "    #'C': (1.5,3.0,4.0),\n",
    "    #'kernel': ('linear', 'sigmoid', 'rbf', 'poly', 'precomputed')\n",
    "    #'degree': (3,1,2,4,5)\n",
    "    #'shrinking': (True, False),\n",
    "    #'probability': (True, False)\n",
    "    #'decision_function_shape': ('ovr','ovo')\n",
    "}\n",
    "\n",
    "svcClsfr.fit(X_train, df.toxicity)\n",
    "print(svcClsfr.score(X_test, df2.toxicity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crazyfox/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nnClsfr = MLPClassifier(alpha = 1, hidden_layer_sizes=(100,20), max_iter=300)\n",
    "\n",
    "# hidden_layer_sizes=(100, ), activation=’relu’, solver=’adam’, alpha=0.0001, batch_size=’auto’, \n",
    "# learning_rate=’constant’, learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, \n",
    "# tol=0.0001, verbose=False, warm_start=False, \n",
    "# momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, \n",
    "# beta_2=0.999, epsilon=1e-08)\n",
    "params = {\n",
    "    #'hidden_layer_sizes': ((100,),(200,),(100,20)),\n",
    "    #'max_iter': (100,200,300)\n",
    "}\n",
    "\n",
    "nnClsfr.fit(X_train, df.toxicity)\n",
    "print(nnClsfr.score(X_test, df2.toxicity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV, for iterating over hyper-parameters of classifiers\n",
    "# Use this for tuning each model\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# gridEst = GridSearchCV(nnClsfr, params).fit(X_train, train_set.toxicity_score)\n",
    "\n",
    "# print(gridEst.best_params_)\n",
    "# print(gridEst.score(X_test, test_set.toxicity_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dtreeClsfr = tree.DecisionTreeClassifier()\n",
    "dtreeClsfr.fit(X_train, df.toxicity)\n",
    "\n",
    "print(dtreeClsfr.score(X_test, df2.toxicity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.768\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "grboostClsfr = GradientBoostingClassifier()\n",
    "grboostClsfr.fit(X_train, df.toxicity)\n",
    "\n",
    "print(grboostClsfr.score(X_test, df2.toxicity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NBclassifier = MultinomialNB()\n",
    "\n",
    "NBclassifier.fit(X_train, df.toxicity)\n",
    "\n",
    "# resultNB = NBclassifier.predict(X_test)\n",
    "    \n",
    "print(NBclassifier.score(X_test, df2.toxicity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.744\n"
     ]
    }
   ],
   "source": [
    "# Classifier, Linear Model\n",
    "from sklearn import linear_model\n",
    "sgd_clsf = linear_model.SGDClassifier(max_iter=1000)\n",
    "sgd_clsf.fit(X_train, df.toxicity)\n",
    "\n",
    "#resultSGD = sgd_clsf.predict(X_test)\n",
    "\n",
    "print(sgd_clsf.score(X_test, df2.toxicity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linSVCclsf = LinearSVC()\n",
    "\n",
    "# (penalty=’l2’, loss=’squared_hinge’, dual=True, tol=0.0001, C=1.0, \n",
    "# multi_class=’ovr’, fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, \n",
    "# random_state=None, max_iter=1000)\n",
    "params = {\n",
    "    \n",
    "}\n",
    "\n",
    "linSVCclsf.fit(X_train, df.toxicity)\n",
    "print(linSVCclsf.score(X_test, df2.toxicity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.744\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=400, max_features=.1)\n",
    "\n",
    "params = {\n",
    "    #'n_estimators': (10,25,50,100,200,400),\n",
    "    #'max_features': (.1,.2,.4,.6,.8,.9)\n",
    "}\n",
    "\n",
    "forest.fit(X_train, df.toxicity)\n",
    "print(forest.score(X_test, df2.toxicity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crazyfox/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "all_clsf = VotingClassifier(estimators=[('multiNB', NBclassifier), ('randForest', forest), ('linSVC', linSVCclsf),\\\n",
    "                                       ('linModel', sgd_clsf), ('logreg', logRegClsfr),\\\n",
    "                                       ('svc', svcClsfr), ('nn', nnClsfr), ('dtree', dtreeClsfr), \\\n",
    "                                        ('grboost', grboostClsfr)])\n",
    "all_clsf.fit(X_train, df.toxicity)\n",
    "print(all_clsf.score(X_test, df2.toxicity))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
